{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61b30fd3-5f70-4c0b-b60d-4325bc977ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 49 files from: /workspaces/group-project-inferra/Data/NNDSS\n",
      "\n",
      "Successfully processed 49 fortnights\n",
      "\n",
      "Final dataset: 76 diseases × 49 fortnights\n",
      "\n",
      "======================================================================\n",
      "✓ FILE SAVED: /workspaces/group-project-inferra/Data/AUS_merged_nndss_all_diseases.xlsx\n",
      "  Size: 19,199 bytes\n",
      "======================================================================\n",
      "\n",
      "✓ COMPLETE! Output saved under Data/: merged_nndss_all_diseases.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PATHS \n",
    "\n",
    "HERE = Path.cwd()\n",
    "REPO_ROOT = next(p for p in [HERE] + list(HERE.parents) if (p / \"Data\").exists())\n",
    "\n",
    "INPUT_DIR = REPO_ROOT / \"Data\" / \"NNDSS\"   # read .xlsx from here\n",
    "OUTPUT_DIR = REPO_ROOT / \"Data\"            # save merged file here\n",
    "\n",
    "# Find Excel files\n",
    "excel_files = sorted([f for f in os.listdir(INPUT_DIR) if f.endswith('.xlsx')])\n",
    "\n",
    "print(f\"Processing {len(excel_files)} files from: {INPUT_DIR}\\n\")\n",
    "\n",
    "# HELPER FUNCTIONS \n",
    "\n",
    "def get_fortnight_from_file(file_path):\n",
    "    try:\n",
    "        df = pd.read_excel(file_path, sheet_name=0, header=None, nrows=10)\n",
    "\n",
    "        for i in range(min(10, len(df))):\n",
    "            for j in range(min(10, len(df.columns))):\n",
    "                cell = str(df.iloc[i, j])\n",
    "                fn_match = re.search(r'FN(\\d+)[/\\s]*(\\d{4})', cell, re.IGNORECASE)\n",
    "                if fn_match:\n",
    "                    return int(fn_match.group(1)), int(fn_match.group(2))\n",
    "\n",
    "        filename = os.path.basename(file_path)\n",
    "        fn_match = re.search(r'fn(\\d+)', filename, re.IGNORECASE)\n",
    "        year_match = re.search(r'(202[3-9])', filename)\n",
    "\n",
    "        if fn_match and year_match:\n",
    "            fn_num = int(fn_match.group(1))\n",
    "            year = int(year_match.group(1))\n",
    "            return fn_num, year\n",
    "\n",
    "        months = {'january': 1, 'february': 2, 'march': 3, 'april': 4, 'may': 5, 'june': 6,\n",
    "                  'july': 7, 'august': 8, 'september': 9, 'october': 10, 'november': 11, 'december': 12}\n",
    "\n",
    "        for month_name, month_num in months.items():\n",
    "            if month_name in filename.lower():\n",
    "                day_match = re.search(r'(\\d{1,2})[_\\s-]' + month_name, filename, re.IGNORECASE)\n",
    "                if day_match and year_match:\n",
    "                    day = int(day_match.group(1))\n",
    "                    fn_num = (month_num - 1) * 2 + (1 if day <= 15 else 2)\n",
    "                    return fn_num, int(year_match.group(1))\n",
    "\n",
    "        return None, None\n",
    "    except:\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def read_nndss_file(file_path):\n",
    "    try:\n",
    "        df = pd.read_excel(file_path, sheet_name=0, header=None)\n",
    "\n",
    "        header_row = None\n",
    "        for idx, row in df.iterrows():\n",
    "            row_str = ' '.join([str(x) for x in row.values if pd.notna(x)])\n",
    "            if 'Disease name' in row_str:\n",
    "                header_row = idx\n",
    "                break\n",
    "\n",
    "        if header_row is None:\n",
    "            return None\n",
    "\n",
    "        df.columns = df.iloc[header_row]\n",
    "        data_start = header_row + 1\n",
    "\n",
    "        while data_start < len(df) and data_start < header_row + 5:\n",
    "            if pd.isna(df.iloc[data_start, 0]) or 'datetime' in str(df.iloc[data_start, 0]).lower():\n",
    "                data_start += 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        data_df = df.iloc[data_start:].copy()\n",
    "\n",
    "        disease_col = None\n",
    "        for col in data_df.columns:\n",
    "            if pd.notna(col) and 'Disease name' in str(col):\n",
    "                disease_col = col\n",
    "                break\n",
    "\n",
    "        total_col = None\n",
    "        for col in data_df.columns:\n",
    "            if pd.notna(col) and 'This reporting period' in str(col):\n",
    "                total_col = col\n",
    "                break\n",
    "\n",
    "        if disease_col is None or total_col is None:\n",
    "            return None\n",
    "\n",
    "        result_df = data_df[[disease_col, total_col]].copy()\n",
    "        result_df.columns = ['Disease', 'Total_Cases']\n",
    "\n",
    "        result_df = result_df[result_df['Disease'].notna()]\n",
    "        result_df['Disease'] = result_df['Disease'].astype(str).str.strip()\n",
    "        result_df = result_df[~result_df['Disease'].str.lower().str.endswith('diseases')]\n",
    "        result_df = result_df[result_df['Disease'] != 'nan']\n",
    "\n",
    "        result_df['Total_Cases'] = pd.to_numeric(result_df['Total_Cases'], errors='coerce')\n",
    "        result_df = result_df[result_df['Total_Cases'].notna()]\n",
    "\n",
    "        return result_df\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "# PROCESS ALL FILES\n",
    "\n",
    "all_data = {}\n",
    "processed_fortnights = {}\n",
    "\n",
    "for filename in excel_files:\n",
    "    file_path = str(INPUT_DIR / filename)\n",
    "\n",
    "    fn_num, year = get_fortnight_from_file(file_path)\n",
    "\n",
    "    if fn_num and year:\n",
    "        column_name = f\"FN{fn_num:02d}_{year}\"\n",
    "\n",
    "        if column_name in processed_fortnights:\n",
    "            continue\n",
    "\n",
    "        df = read_nndss_file(file_path)\n",
    "\n",
    "        if df is not None and len(df) > 0:\n",
    "            processed_fortnights[column_name] = filename\n",
    "\n",
    "            for _, row in df.iterrows():\n",
    "                disease = row['Disease']\n",
    "                total = row['Total_Cases']\n",
    "\n",
    "                if disease not in all_data:\n",
    "                    all_data[disease] = {}\n",
    "\n",
    "                all_data[disease][column_name] = total\n",
    "\n",
    "print(f\"Successfully processed {len(processed_fortnights)} fortnights\\n\")\n",
    "\n",
    "\n",
    "# CREATE MERGED DATAFRAME\n",
    "\n",
    "merged_df = pd.DataFrame(all_data).T\n",
    "\n",
    "def sort_key(col):\n",
    "    match = re.search(r'FN(\\d+)_(\\d{4})', col)\n",
    "    if match:\n",
    "        return (int(match.group(2)), int(match.group(1)))\n",
    "    return (9999, 99)\n",
    "\n",
    "sorted_columns = sorted(merged_df.columns, key=sort_key)\n",
    "merged_df = merged_df[sorted_columns]\n",
    "\n",
    "merged_df.reset_index(inplace=True)\n",
    "merged_df.rename(columns={'index': 'Disease_Name'}, inplace=True)\n",
    "merged_df = merged_df.fillna(0)\n",
    "\n",
    "print(f\"Final dataset: {merged_df.shape[0]} diseases × {merged_df.shape[1]-1} fortnights\")\n",
    "\n",
    "\n",
    "# SAVE ONLY THE MERGED FILE\n",
    "\n",
    "output_file = str(OUTPUT_DIR / \"AUS_merged_nndss_all_diseases.xlsx\")\n",
    "merged_df.to_excel(output_file, index=False, engine='openpyxl')\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"✓ FILE SAVED: {output_file}\")\n",
    "print(f\"  Size: {os.path.getsize(output_file):,} bytes\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "print(\"\\n✓ COMPLETE! Output saved under Data/: merged_nndss_all_diseases.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c7fb06a-7cf8-48c6-8335-4f38c851f593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== BASIC INFO ===\n",
      "Shape: (76, 50)\n",
      "Columns: ['Disease_Name', 'FN01_2024', 'FN02_2024', 'FN03_2024', 'FN04_2024', 'FN05_2024', 'FN06_2024', 'FN07_2024', 'FN08_2024', 'FN09_2024'] ...\n",
      "                   Disease_Name  FN01_2024  FN02_2024  FN03_2024  FN04_2024  \\\n",
      "0  Hepatitis B (newly acquired)          4          2          0          5   \n",
      "1     Hepatitis B (unspecified)        303        188        206        210   \n",
      "2  Hepatitis C (newly acquired)         58         22         24         24   \n",
      "3     Hepatitis C (unspecified)        466        279        235        272   \n",
      "4                   Hepatitis D          4          2          5          6   \n",
      "\n",
      "   FN05_2024  FN06_2024  FN07_2024  FN08_2024  FN09_2024  ...  FN15_2025  \\\n",
      "0          2          4          2          4          3  ...          2   \n",
      "1        223        222        242        251        259  ...        196   \n",
      "2         34         29         26         13         14  ...         22   \n",
      "3        279        291        264        260        231  ...        264   \n",
      "4          4          3          4          4         10  ...          7   \n",
      "\n",
      "   FN16_2025  FN17_2025  FN18_2025  FN19_2025  FN20_2025  FN21_2025  \\\n",
      "0          1          2          1          4          1          2   \n",
      "1        194        220        218        231        220        181   \n",
      "2         22         43         25         24         37         35   \n",
      "3        265        221        250        228        241        236   \n",
      "4          9          3          5          7          2          5   \n",
      "\n",
      "   FN22_2025  FN23_2025  FN24_2025  \n",
      "0          4          4          1  \n",
      "1        230        189        193  \n",
      "2         51         30         33  \n",
      "3        251        244        270  \n",
      "4          5          2          3  \n",
      "\n",
      "[5 rows x 50 columns]\n",
      "\n",
      "=== MISSINGNESS (top 10 columns) ===\n",
      "Disease_Name    0.0\n",
      "FN01_2024       0.0\n",
      "FN02_2024       0.0\n",
      "FN03_2024       0.0\n",
      "FN04_2024       0.0\n",
      "FN05_2024       0.0\n",
      "FN06_2024       0.0\n",
      "FN07_2024       0.0\n",
      "FN08_2024       0.0\n",
      "FN09_2024       0.0\n",
      "dtype: float64\n",
      "\n",
      "=== DESCRIPTIVE STATS (first few FN columns) ===\n",
      "          FN01_2024     FN02_2024     FN03_2024     FN04_2024     FN05_2024\n",
      "count     76.000000     76.000000     76.000000     76.000000     76.000000\n",
      "mean    1012.789474    528.197368    457.868421    471.381579    500.776316\n",
      "std     5061.276999   2457.179218   1966.775143   1859.756471   1851.165259\n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000\n",
      "25%        0.000000      0.000000      0.000000      0.000000      0.000000\n",
      "50%        4.000000      2.000000      2.000000      2.500000      2.000000\n",
      "75%      122.750000     63.000000     58.250000     73.750000     83.000000\n",
      "max    42391.000000  20444.000000  16105.000000  14767.000000  13946.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# PATHS\n",
    "\n",
    "HERE = Path.cwd()\n",
    "REPO_ROOT = next(p for p in [HERE] + list(HERE.parents) if (p / \"Data\").exists())\n",
    "\n",
    "MERGED_FILE = REPO_ROOT / \"Data\" / \"AUS_merged_nndss_all_diseases.xlsx\"\n",
    "\n",
    "# Load merged dataset\n",
    "\n",
    "df = pd.read_excel(MERGED_FILE, engine=\"openpyxl\")\n",
    "\n",
    "print(\"\\n=== BASIC INFO ===\")\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist()[:10], \"...\")\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "# Basic exploration (like COVID)\n",
    "\n",
    "print(\"\\n=== MISSINGNESS (top 10 columns) ===\")\n",
    "missing_pct = (df.isna().mean() * 100).sort_values(ascending=False)\n",
    "print(missing_pct.head(10))\n",
    "\n",
    "print(\"\\n=== DESCRIPTIVE STATS (first few FN columns) ===\")\n",
    "num_cols = [c for c in df.columns if c.startswith(\"FN\")]\n",
    "print(df[num_cols[:5]].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "923a7dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved Measles to: /workspaces/group-project-inferra/Data/AUS_measles.xlsx\n",
      "   Rows: 1, FN columns: 49\n",
      "✅ Saved RSV to: /workspaces/group-project-inferra/Data/AUS_rsv.xlsx\n",
      "   Rows: 1, FN columns: 49\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# PATHS\n",
    "HERE = Path.cwd()\n",
    "REPO_ROOT = next(p for p in [HERE] + list(HERE.parents) if (p / \"Data\").exists())\n",
    "\n",
    "MERGED_FILE = REPO_ROOT / \"Data\" / \"AUS_merged_nndss_all_diseases.xlsx\"\n",
    "OUT_DIR = REPO_ROOT / \"Data\"\n",
    "\n",
    "df = pd.read_excel(MERGED_FILE, engine=\"openpyxl\")\n",
    "\n",
    "fn_cols = [c for c in df.columns if re.match(r\"FN\\d+_\\d{4}\", str(c))]\n",
    "id_col = \"Disease_Name\"\n",
    "\n",
    "def extract_and_save_xlsx(disease_label: str, patterns: list[str]):\n",
    "    mask = df[id_col].astype(str).str.contains(\"|\".join(patterns), case=False, na=False, regex=True)\n",
    "    sub = df[mask].copy()\n",
    "\n",
    "    if sub.empty:\n",
    "        print(f\"❌ {disease_label}: not found. Try updating patterns.\")\n",
    "        return\n",
    "\n",
    "    out_file = OUT_DIR / f\"AUS_{disease_label.lower().replace(' ', '_')}.xlsx\"\n",
    "    sub.to_excel(out_file, index=False, engine=\"openpyxl\")\n",
    "\n",
    "    print(f\"✅ Saved {disease_label} to: {out_file}\")\n",
    "    print(f\"   Rows: {len(sub)}, FN columns: {len(fn_cols)}\")\n",
    "\n",
    "# Save both files\n",
    "extract_and_save_xlsx(\"Measles\", [r\"\\bmeasles\\b\"])\n",
    "extract_and_save_xlsx(\"RSV\", [r\"\\brsv\\b\", r\"respiratory\\s+syncytial\\s+virus\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "tracking": {
   "editors": {
    "romore@syr.edu": 195
   },
   "history": [
    {
     "bytes": 497,
     "edit_time_seconds": 120,
     "timestamp": "2026-02-09T02:49:43.115Z",
     "user": "romore@syr.edu"
    },
    {
     "bytes": 8715,
     "edit_time_seconds": 75,
     "timestamp": "2026-02-09T02:50:59.037Z",
     "user": "romore@syr.edu"
    }
   ],
   "last_edit_by": "romore@syr.edu",
   "total_edit_time_seconds": 195
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
